---
title: "New paper at ACSOS I care especially about"
excerpt: ""
tags:
  - ACSOS2023
  - pheromone-based communication
  - multi-agent reinforcement learning
  - swarm intelligence
  - learning to communicate
  - coordination
  - publication
header:
  teaser: /assets/acsos2023-rl-swarms-title.png
---

Quick post to share a new paper by me and [Franco Zambonelli](http://www.agentgroup.unimore.it/Zambonelli/) accepted at [ACSOS 2023](https://2023.acsos.org/details/acsos-2023-papers/10/Learning-Stigmergic-Communication-for-Self-organising-Coordination) --- will be presented Wednesday 27 Sep 2023 at ~14:00, slides already available [here](https://smarianimore.github.io/2023-acsos-RL-swarms/) :)

![image-center]({{ site.url }}{{ site.baseurl }}/assets/acsos2023-rl-swarms-title.png){: .align-center}

![image-center]({{ site.url }}{{ site.baseurl }}/assets/acsos2023-rl-swarms-abstract.png){: .align-center}

I care about all of my papers (quite obviously), don't get me wrong, but **I care particularly about this one** as it is quite a novel field of research for me, hence early feedback is extremely valuable (more than usual).

In brief, the paper proposes to **learn communication policies** amongst agents in a multi-agent systems to achieve self-organisation.
The study is motivated by the fact that bottom-up coordination strategies are difficult to design, are often tightly tailored to the goal to be achieved by the MAS, and the behaviour that the designer wants to inject in the system is often finely tuned to the specific problem at hand via extensive simulation sessions.
Having agents learn such strategies from scratch may free the designer from this burden, and also give **greater adaptiveness** to the resulting agents' behaviours.

The learning environment is a simple yet expressive pheromone-based scenario: slime molds aggregation.
In a slime mold, different cells communicate the need for aggregation (e.g. to face danger) by locally depositing pheromone. 
Cells wander randomly but prefer areas with stronger pheromone scent---the pheromone evaporates over time.
In this way, clusters of slimes appear by emergence when needed, and disband when not needed anymore.

Our general goal specialised to this scenario becomes then to let the slime agents learn **when** (i.e. in what circumstances, in which system state) to deposit and follow pheromone to successfully cluster.

The key results achieved are:
  - **independent learning* works (fully decentralised)
  - learnt policies **outperform** the ones usually hard-coded
  - learnt policies **diverge** despite agents' homogeneity, and this is key to self-organisation
  - learnt communication policies **adapt* to changing goals (where the goal is the task to achieve by the MAS---the learning goal is fixed instead, of course)

As pheromone-based communication (like other stigmergic communication mechanisms) is widely studied and used in both MAS and swarm robotics, this research line has potential impact in this application fields.

<iframe width="560" height="315" src="https://www.youtube.com/embed/1qUBvnw3tbU?si=vtMuwMkdZYbRzMhf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

![image-center]({{ site.url }}{{ site.baseurl }}/assets/acsos2023-rl-swarms-results.png){: .align-center}

Feel free to [contact me](mailto:stefano.mariani@unimore.it) for a pre-print, any inquiry, or even better **to join us** in this research :)

Peace.
