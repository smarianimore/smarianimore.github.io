---
title: "PAAMS paper pdf available!"
excerpt: ""
tags:
  - student
  - PAAMS2023
  - causal discovery
  - multi-agent causal learning
  - smart home
  - coordination
  - publication
header:
  teaser: /assets/2023-paams-causal.png
---

As anticipated in a previous post, an extended version of our AMAAS 2023 abstract on **multi-agent causal discovery** has been accepted at PAAMS, and is now available online in the proceedings: 
Kudos to the brilliant master student [Pasquale Roseti](https://www.linkedin.com/in/pasquale-roseti-a5b513238/), that co-authored with me and [Franco Zambonelli](http://www.agentgroup.unimore.it/Zambonelli/) this novel version of his first scientific publication :)

![no-alignment]({{ site.url }}{{ site.baseurl }}/assets/2023-paams-causal.png)

In brief, the paper proposes a *multi-agent protocol* to collaboratively **discover (= learn) the causal structure** relating variables of interest (e.g. sensors and actuators) in a distributed network.
The study is motivated by the fact that learning not only *correlations* amongst variables (as classical statistical ML does) but actual causal relations (as per level 2 of [Pearl's ladder of causation](http://lgmoneda.github.io/2018/06/01/the-book-of-why.html)) is crucial to let agents proficiently understand situations and plan accordingly how to achieve their goals in unknown environments, also favouring *explainability* of decisions taken by AI.

Evaluation of the protocol has been carried out in a simulated smart home environment.

![no-alignment]({{ site.url }}{{ site.baseurl }}/assets/2023-paams-causal-scenario.png)

The key results achieved are:
  - learning **accuracy is always better** with multi-agent learning than with single-agent learning
  - learning **performance is always better** in the multi-agent case, too, to an extent increasing as the causal network size and complexity increases (e.g. number of edges and indirect causal paths length)

The core idea of the approach is to leverage any existing causal discovery algorithm locally to each agent, then refine the locally learnt model by **coordinating interventions** with other agents sharing the environment, even when no overlap exists amongst the set of known variables.
In this way, both the agent requesting help (e.g. $A_1$, agent red) and the one giving help (e.g. $A_2$, agent blue) can improve their local model!

![no-alignment]({{ site.url }}{{ site.baseurl }}/assets/2023-paams-causal-agent1.png)

![no-alignment]({{ site.url }}{{ site.baseurl }}/assets/2023-paams-causal-agent2.png)

Feel free to [contact me](mailto:stefano.mariani@unimore.it) for a pre-print or any further inquiry :)

Peace.
